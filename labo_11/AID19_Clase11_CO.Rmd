---
title: "AID Clase 11"
author: "Cecilia Oliva"
date: "6 de julio de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<br>
<br>

<center> <h1>QDA</h1> </center>

<br>

### <span style="color:darkred">Ejemplo 1: Generamos un conjunto de datos simulados.</span>
<br>

```{r echo=TRUE}
set.seed(1234)
grupoA_x <- seq(from = -3, to = 4, length.out = 100)-+ rnorm(100, sd = 1)
grupoA_y <- 6 + 0.15 * grupoA_x - 0.3 * grupoA_x^2 + rnorm(100, sd = 1)
grupoA <- data.frame(variable_z = grupoA_x, variable_w = grupoA_y, grupo = "A")

grupoB_x <- rnorm(n = 100, mean = 0.5, sd = 0.8)
grupoB_y <- rnorm(n = 100, mean = 2, sd = 0.9)
grupoB <- data.frame(variable_z = grupoB_x, variable_w = grupoB_y, grupo = "B")

datos <- rbind(grupoA, grupoB)
head(datos)
plot(datos[, 1:2], col = datos$grupo, pch = 19)
```

Se aprecia en este gráfico que los datos no son linealmente separables, es probable que QDA ofrezca una mejor alternativa que LDA.


```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(ggplot2)
library(ggpubr)
```

```{r echo=TRUE}
#library(corpcor)
#library(Hotelling)
```

Superponemos los histogramas de las variables z y w por grupo:

```{r echo=TRUE}
p1 <- ggplot(data = datos, aes(x = variable_z, fill = grupo)) +
  geom_histogram(position = "identity", alpha = 0.5)
p2 <- ggplot(data = datos, aes(x = variable_w, fill = grupo)) +
  geom_histogram(position = "identity", alpha = 0.5)
ggarrange(p1, p2, nrow = 2, common.legend = TRUE, legend = "bottom")
```


Se ve que si bien se superponen tienen distribuciones bien distintas sobre todo para la variable w.

<br>
<h4>Análisis diagnóstico de los supuestos del modelo</h4>
<br>
Representación mediante histograma de cada variable para cada grupo 

```{r echo=TRUE}
par(mfcol = c(2, 2))
for (k in 1:2) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$grupo)[i]
    x <- datos[datos$grupo == i0, j0]
    hist(x, proba = T, col = grey(0.8), main = paste("grupo", i0),
         xlab = j0)
    lines(x0, dnorm(x0, mean(x), sd(x)), col = "red", lwd = 2)
  }
}
```

Se aprecia que la normalidad ajusta en forma razonable a los histogramas.

QQplot normal por variable para cada grupo:
  
```{r echo=TRUE}
par(mfcol = c(2, 2))
for (k in 1:2) {
  j0 <- names(datos)[k]
  x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
  for (i in 1:2) {
    i0 <- levels(datos$grupo)[i]
    x <- datos[datos$grupo == i0, j0]
    qqnorm(x, main = paste(i0, j0), pch = 19, col = i + 1)
    qqline(x)
  }
}

par(mfcol = c(1, 1))
```

Contraste de normalidad Shapiro-Wilk para cada variable en cada grupo.

```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(reshape2)
library(dplyr)
```

```{r echo=TRUE}
#library(reshape2)
#library(dplyr)
```

```{r echo=TRUE}
datos_tidy <- melt(datos, value.name = "valor")
datos_tidy %>%
  group_by(grupo, variable) %>% 
  summarise(p_value_Shapiro.test = round(shapiro.test(valor)$p.value,5))
```


La variable w no satisface normalidad univariada en el grupo A.

<br>
<h4>Análisis de normalidad multivariada</h4>
<br>
```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(mvnormtest)
library(MASS)
```

```{r echo=TRUE}
#library(mvnormtest)
#library(MASS)
```
```{r echo=TRUE}
mshapiro.test(t(datos[,-3]))
```
<br>
<h4>Analizamos igualdad de matrices de varianzas y covarianzas:</h4>
```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(biotools)
```
```{r echo=TRUE}
#recordar instalar los paquetes si no están instalados aún
#library(biotools)
```
```{r echo=TRUE}
boxM(data = datos[, 1:2], grouping = datos[, 3])
```
No se verifica la normalidad multivariada. Si bien QDA tiene cierta robustez frente a la falta de normalidad multivariante, es importante tenerlo en cuenta en la conclusión del análisis. 

Tampoco se verifica la igualdad de matrices de varianzas y covarianzas

<br>
<h4>Modelo QDA:</h4>
<br>
```{r echo=TRUE}
modelo_qda <- qda(grupo ~ variable_z + variable_w, data = datos,CV=TRUE)
#modelo_qda
table(modelo_qda$class,datos$grupo)
mean(modelo_qda$class==datos$grupo) # tasa de buena clasificación del discr. cuadrático


### con muestra de entrenamiento y validación
set.seed(102030)# fijo la semilla para que todos obtengamos los mismos resultados
train=sample(1:200,150)
df_train=data.frame(datos[train,])
df_test=data.frame(datos[-train,])
qda.train=qda(grupo~ variable_z + variable_w, data = df_train)

qda_predTest = predict(qda.train, df_test)
qda_class = predict(qda.train, df_test)$class
table(qda_class, df_test$grupo)
mean(qda_class== df_test$grupo) # tasa de buena clasificación

```

<br>
<h4>También podemos aplicar qda robusto (QdaCov, Robust Quadratic Discriminant Analysis)</h4>
<br>

```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(rrcov)
```

```{r echo=TRUE}
#library(rrcov)
```

```{r echo=TRUE}
rob.mcd=QdaCov( datos$grupo~., data = datos)
predict(rob.mcd)@classification
table(predict(rob.mcd)@classification,datos$grupo)
mean(predict(rob.mcd)@classification==datos$grupo) # tasa de buena clasif. ingenua del discr. robusto
```

Probemos otras alternativas robustas:

```{r echo=TRUE}
rob.sde=QdaCov(datos$grupo~., data = datos, method="sde")
predict(rob.mcd)@classification
table(predict(rob.sde)@classification,datos$grupo)
mean(predict(rob.sde)@classification==datos$grupo) # tasa de buena clasif. ingenua del discr. robusto


rob.M=QdaCov(datos$grupo~., data = datos, method="M")
predict(rob.mcd)@classification
table(predict(rob.M)@classification,datos$grupo)
mean(predict(rob.M)@classification==datos$grupo) # tasa de buena clasif. ingenua del discr. robusto


roblog=QdaCov(datos$grupo~., data = datos, method=CovControlOgk())
predict(rob.mcd)@classification
table(predict(roblog)@classification,datos$grupo)
mean(predict(roblog)@classification==datos$grupo) # tasa de buena clasif. ingenua del discr. robusto
```
Qué se observa??

<br>

### <span style="color:darkred">Ejemplo 2</span>
<br>

Se observaron	dos grupos de salmones de Alaska y Canadá y se quiere	determinar el origen de los mismos en función de los datos obtenidos.

```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(ggplot2)
library(ggpubr)
library(readxl)
```

```{r echo=TRUE}
#library(ggplot2)
#library(ggpubr)
#library(readxl)
```
```{r echo=TRUE}
salmon <- read_excel("D:/MaestriaDataMining-DeptoCompu/AID/AIDproject/salmon.xlsx")
head(salmon)
Origen=factor(salmon$origen)
p1=ggplot(aes(x=aguadulce,y=mar,fill=Origen,color=Origen),data=salmon)+
  geom_point(aes(x=aguadulce,y=mar))
p1
```

Observamos las variables candidatas a discriminar.

```{r echo=TRUE}
pdul <- ggplot(salmon, aes(aguadulce, colour = Origen)) +
  geom_freqpoly(binwidth = 10)

pmar <-ggplot(salmon, aes(mar, colour = Origen)) +
  geom_freqpoly(binwidth = 10)
ggarrange(pdul, pmar, nrow = 2, common.legend = TRUE, legend = "bottom")
```
<br>
<br>
<h4>Veamos si se satisfacen los supuestos de homoscedasticidad y normalidad multivariada.</h4>
<br>
```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(mvnormtest)

```
```{r echo=TRUE}
#library(mvnormtest)
mshapiro.test(t(salmon[,-1]))
```
No rechazamos la normalidad multivariada

```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(biotools)
library(MASS)

```

```{r echo=TRUE}
#library(biotools)
#library(MASS)

```
```{r echo=TRUE}
boxM(data =salmon[,-1], grouping = Origen)
```
No se satisface la homoscedasticidad!! Intentamos discriminante cuadrático.

<br>
<h4>Clasificacion ingenua</h4>
<br>

```{r echo=TRUE}
##clasificacion ingenua
salmon_lda0 <- lda(Origen ~ aguadulce+mar, data = salmon)
salmon_lda0
salmon_qda0 <- qda(Origen ~ aguadulce+mar, data = salmon)
salmon_qda0


##LDA

prediccionesLda <- predict(object = salmon_lda0, newdata = salmon[,-1]) 
table(salmon$origen, prediccionesLda$class, dnn = c("Origen real", "Origen predicho"))

error_ingenuo_lda<- mean(salmon$origen != prediccionesLda$class) * 100
error_ingenuo_lda#7%


##QDA

prediccionesQda <- predict(object = salmon_qda0, newdata = salmon[,-1]) 
table(salmon$origen, prediccionesQda$class, dnn = c("Origen real", "Origen predicho"))

error_ingenuo_qda<- mean(salmon$origen != prediccionesQda$class) * 100
error_ingenuo_qda#7%
```

<br>
<h4>Clasificación cv-loo</h4>
<br>
```{r echo=TRUE}

## clasificación cv-loo
salmon_lda <- lda(Origen ~ aguadulce+mar, data = salmon,CV=TRUE)
#salmon_lda
salmon_qda <- qda(Origen ~ aguadulce+mar, data = salmon,CV=TRUE)
#salmon_qda


##LDA

table(salmon_lda$class,Origen)
TasaBuenaclasif_lda<-mean(salmon_lda$class==Origen)#0.93 # tasa de buena clasificación del discr lineal
TasaBuenaclasif_lda
error_cvloo_lda<-mean(salmon_lda$class!=Origen)#0.07 # tasa de error
error_cvloo_lda


##QDA

table(salmon_qda$class,Origen)
TasaBuenaclasif_qda<-mean(salmon_qda$class==Origen)# tasa de buena clasificación del discr cuadrático
TasaBuenaclasif_qda
error_cvloo_qda<-mean(salmon_qda$class!=Origen)# tasa de error
error_cvloo_qda
```

<br>
<h4>Clasificación con entrenamiento y validación</h4>
<br>

```{r echo=TRUE}

## clasificación con entrenamiento y validación
set.seed(2019)
entrenamiento<-sample(1:100,70)
validacion<-c(1:100)[-entrenamiento]
salmon_lda1 <- lda(origen ~ aguadulce+mar, data = salmon[entrenamiento,])
salmon_lda1
salmon_qda1 <- qda(origen ~ aguadulce+mar, data = salmon[entrenamiento,])
salmon_qda1

##LDA

prediccionesLda_2 <- predict(object = salmon_lda1, newdata = salmon[validacion,-1]) 
table(salmon$origen[validacion], prediccionesLda_2$class, dnn = c("Origen real", "Origen predicho"))

error_test_lda<- mean(salmon$origen[validacion] != prediccionesLda_2$class) * 100
error_test_lda#6.666667%


##QDA

prediccionesQda_2<- predict(object = salmon_qda1, newdata = salmon[validacion,-1]) 
table(salmon$origen[validacion], prediccionesQda_2$class, dnn = c("Origen real", "Origen predicho"))

error_test_qda<- mean(salmon$origen[validacion] != prediccionesQda_2$class) * 100
error_test_qda#6.666667%

```
Es razonable??

<br>
<br>
<h4>Gráficos de las particiones según QDA y LDA</h4>

```{r include=FALSE}
#recordar instalar los paquetes si no están instalados aún
library(klaR)

```

```{r echo=TRUE}
#library(klaR)

```
```{r echo=TRUE}
Origen=factor(salmon$origen)
partimat(Origen ~ mar+aguadulce, data = salmon, method = "qda", 
         imageplot = TRUE,col.mean=1,image.colors = c("lightgrey","gold"))
partimat(Origen ~ mar+aguadulce, data = salmon, method = "lda", col.mean=1,
         imageplot = TRUE,image.colors = c("lightgrey","gold"))

```